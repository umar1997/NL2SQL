{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91323633",
   "metadata": {},
   "source": [
    "# Basic MLM\n",
    "\n",
    "Links:  \n",
    "https://towardsdatascience.com/masked-language-modelling-with-bert-7d49793e5d2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "430e34c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 1.10.0+cu102\n",
      "Transformer Version: 4.19.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "print('Torch Version: {}'.format(torch.__version__))\n",
    "print('Transformer Version: {}'.format(transformers.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76a96844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from transformers import BertTokenizer, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "504e3113",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_checkpoint = 'bert-base-uncased'\n",
    "model_checkpoint = \"distilroberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ee61bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_checkpoint, do_lower_case=False, use_fast=True)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61f24107",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"After Abraham Lincoln won the November 1860 presidential \"\n",
    "        \"election on an anti-slavery platform, an initial seven \"\n",
    "        \"slave states declared their secession from the country \"\n",
    "        \"to form the Confederacy. War broke out in April 1861 \"\n",
    "        \"when secessionist forces attacked Fort Sumter in South \"\n",
    "        \"Carolina, just over a month after Lincoln's \"\n",
    "        \"inauguration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2783a1a6",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19825230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b642224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,   100,   100,   100,  2180,  1996,   100,  7313,  4883,  2602,\n",
       "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
       "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
       "          1996,   100,  1012,   100,  3631,  2041,  1999,   100,  6863,  2043,\n",
       "         22965,  2923,  2749,  4457,   100,   100,  1999,   100,   100,  1010,\n",
       "          2074,  2058,  1037,  3204,  2044,   100,  1005,  1055, 17331,  1012,\n",
       "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b18037",
   "metadata": {},
   "source": [
    "### Create Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be6f32c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,   100,   100,   100,  2180,  1996,   100,  7313,  4883,  2602,\n",
       "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
       "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
       "          1996,   100,  1012,   100,  3631,  2041,  1999,   100,  6863,  2043,\n",
       "         22965,  2923,  2749,  4457,   100,   100,  1999,   100,   100,  1010,\n",
       "          2074,  2058,  1037,  3204,  2044,   100,  1005,  1055, 17331,  1012,\n",
       "           102]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4391c956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,   100,   100,   100,  2180,  1996,   100,  7313,  4883,  2602,\n",
       "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
       "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
       "          1996,   100,  1012,   100,  3631,  2041,  1999,   100,  6863,  2043,\n",
       "         22965,  2923,  2749,  4457,   100,   100,  1999,   100,   100,  1010,\n",
       "          2074,  2058,  1037,  3204,  2044,   100,  1005,  1055, 17331,  1012,\n",
       "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[  101,   100,   100,   100,  2180,  1996,   100,  7313,  4883,  2602,\n",
       "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
       "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
       "          1996,   100,  1012,   100,  3631,  2041,  1999,   100,  6863,  2043,\n",
       "         22965,  2923,  2749,  4457,   100,   100,  1999,   100,   100,  1010,\n",
       "          2074,  2058,  1037,  3204,  2044,   100,  1005,  1055, 17331,  1012,\n",
       "           102]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['labels'] = inputs.input_ids.detach().clone()\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6376beba",
   "metadata": {},
   "source": [
    "### Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "084d8014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8400, 0.4681, 0.6857, 0.4110, 0.6420, 0.2889, 0.2432, 0.7263, 0.9982,\n",
       "         0.4042, 0.0242, 0.8994, 0.5887, 0.1267, 0.3324, 0.5458, 0.3493, 0.1375,\n",
       "         0.8353, 0.3522, 0.6388, 0.6152, 0.4932, 0.5298, 0.7013, 0.0383, 0.4491,\n",
       "         0.7716, 0.0639, 0.4459, 0.8733, 0.2705, 0.4141, 0.4742, 0.0328, 0.2086,\n",
       "         0.7248, 0.4617, 0.9138, 0.6629, 0.8560, 0.0909, 0.6473, 0.4355, 0.4463,\n",
       "         0.1385, 0.7687, 0.4634, 0.1919, 0.3024, 0.5737, 0.5893, 0.5354, 0.0651,\n",
       "         0.2776, 0.5156, 0.2981, 0.5315, 0.5661, 0.1806, 0.7637]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82dd2ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "          True, False, False,  True, False, False, False,  True, False, False,\n",
       "         False, False, False, False, False,  True, False, False,  True, False,\n",
       "         False, False, False, False,  True, False, False, False, False, False,\n",
       "         False,  True, False, False, False,  True, False, False, False, False,\n",
       "         False, False, False,  True, False, False, False, False, False, False,\n",
       "         False]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_arr = rand < 0.15\n",
    "mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a492774f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         False]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# special tokens such as CLS or SEP tokens (101 and 102 respectively)\n",
    "(inputs.input_ids != 101) * (inputs.input_ids != 102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48a997fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "          True, False, False,  True, False, False, False,  True, False, False,\n",
       "         False, False, False, False, False,  True, False, False,  True, False,\n",
       "         False, False, False, False,  True, False, False, False, False, False,\n",
       "         False,  True, False, False, False,  True, False, False, False, False,\n",
       "         False, False, False,  True, False, False, False, False, False, False,\n",
       "         False]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * (inputs.input_ids != 102)\n",
    "mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "930221c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 13, 17, 25, 28, 34, 41, 45, 53]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elements to mask\n",
    "selection = torch.flatten((mask_arr[0]).nonzero()).tolist()\n",
    "selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4021b619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,   100,   100,   100,  2180,  1996,   100,  7313,  4883,  2602,\n",
       "           103,  2019,  3424,   103,  8864,  4132,  1010,   103,  3988,  2698,\n",
       "          6658,  2163,  4161,  2037, 22965,   103,  1996,  2406,   103,  2433,\n",
       "          1996,   100,  1012,   100,   103,  2041,  1999,   100,  6863,  2043,\n",
       "         22965,   103,  2749,  4457,   100,   103,  1999,   100,   100,  1010,\n",
       "          2074,  2058,  1037,   103,  2044,   100,  1005,  1055, 17331,  1012,\n",
       "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[  101,   100,   100,   100,  2180,  1996,   100,  7313,  4883,  2602,\n",
       "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
       "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
       "          1996,   100,  1012,   100,  3631,  2041,  1999,   100,  6863,  2043,\n",
       "         22965,  2923,  2749,  4457,   100,   100,  1999,   100,   100,  1010,\n",
       "          2074,  2058,  1037,  3204,  2044,   100,  1005,  1055, 17331,  1012,\n",
       "           102]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids[0, selection] = 103\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebce5a2",
   "metadata": {},
   "source": [
    "### Calculate Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e691516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'logits'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8761edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.1916, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acff2a24",
   "metadata": {},
   "source": [
    "# Train with MLM\n",
    "\n",
    "Link:  \n",
    "https://www.youtube.com/watch?v=R6hcxMMOrPE&ab_channel=JamesBriggs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f973ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "663991bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_checkpoint = 'bert-base-uncased'\n",
    "model_checkpoint = 'distilroberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc2a154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_checkpoint, do_lower_case=False, use_fast=True)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c822b6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9c0dc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From my grandfather Verus I learned good morals and the government of my temper.',\n",
       " 'From the reputation and remembrance of my father, modesty and a manly character.',\n",
       " 'From my mother, piety and beneficence, and abstinence, not only from evil deeds, but even from evil thoughts; and further, simplicity in my way of living, far removed from the habits of the rich.',\n",
       " 'From my great-grandfather, not to have frequented public schools, and to have had good teachers at home, and to know that on such things a man should spend liberally.',\n",
       " \"From my governor, to be neither of the green nor of the blue party at the games in the Circus, nor a partizan either of the Parmularius or the Scutarius at the gladiators' fights; from him too I learned endurance of labour, and to want little, and to work with my own hands, and not to meddle with other people's affairs, and not to be ready to listen to slander.\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./clean.txt', 'r') as fp:\n",
    "    text = fp.read().split('\\n')\n",
    "    \n",
    "text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d055103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,   100,  2026,  ...,     0,     0,     0],\n",
       "        [  101,   100,  1996,  ...,     0,     0,     0],\n",
       "        [  101,   100,  2026,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,   100,  2185,  ...,     0,     0,     0],\n",
       "        [  101,   100, 15223,  ...,     0,     0,     0],\n",
       "        [  101,   100,  3288,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(text, return_tensors='pt', max_length=512, truncation=True, padding='max_length')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "794996d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['labels'] = inputs.input_ids.detach().clone()\n",
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dbe0bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,   100,  2026,  ...,     0,     0,     0],\n",
       "        [  101,   100,  1996,  ...,     0,     0,     0],\n",
       "        [  101,   100,  2026,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,   100,  2185,  ...,     0,     0,     0],\n",
       "        [  101,   100, 15223,  ...,     0,     0,     0],\n",
       "        [  101,   100,  3288,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[  101,   100,  2026,  ...,     0,     0,     0],\n",
       "        [  101,   100,  1996,  ...,     0,     0,     0],\n",
       "        [  101,   100,  2026,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,   100,  2185,  ...,     0,     0,     0],\n",
       "        [  101,   100, 15223,  ...,     0,     0,     0],\n",
       "        [  101,   100,  3288,  ...,     0,     0,     0]])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccccfa23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False,  True, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False,  True, False,  ..., False, False, False],\n",
       "        [False, False,  True,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CLS 101, SEP 102, PAD 0\n",
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "           (inputs.input_ids != 102) * (inputs.input_ids != 0)\n",
    "mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66993da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([507, 512])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e70f470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 6, 12, 15],\n",
       " [5, 10, 16],\n",
       " [1, 4, 5, 7, 14, 17, 24, 27, 31, 33, 36, 42],\n",
       " [4, 5, 10, 11, 12, 20],\n",
       " [3, 10, 24, 28, 35, 41, 47, 48, 51, 52, 53, 59, 73, 77]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take indices of True values for each row\n",
    "selection = []\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )\n",
    "    \n",
    "selection[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5060a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101,  100, 2026,  ...,    0,    0,    0],\n",
       "        [ 101,  100, 1996,  ...,    0,    0,    0],\n",
       "        [ 101,  103, 2026,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101,  103, 2185,  ...,    0,    0,    0],\n",
       "        [ 101,  100,  103,  ...,    0,    0,    0],\n",
       "        [ 101,  100, 3288,  ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    inputs.input_ids[i, selection[i]] = 103\n",
    "    \n",
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef0f5bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        # Here key is\n",
    "        # dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "    \n",
    "# DataLoader requires these two methods __getitem__ and __len__\n",
    "# __len__ to check length of dataset it's looking at\n",
    "# __getitem__ Dictionary formatted batch of those items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f34568d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CustomDataset at 0x7f16e36bdd00>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = CustomDataset(inputs)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cd07810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f16e36bd1c0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5a6d904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 5e-05\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eab36ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "538d3771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForMaskedLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Activate train mode\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1883e407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': <__main__.CustomDataset at 0x7f16e36bdd00>,\n",
       " 'num_workers': 0,\n",
       " 'prefetch_factor': 2,\n",
       " 'pin_memory': False,\n",
       " 'timeout': 0,\n",
       " 'worker_init_fn': None,\n",
       " '_DataLoader__multiprocessing_context': None,\n",
       " '_dataset_kind': 0,\n",
       " 'batch_size': 16,\n",
       " 'drop_last': False,\n",
       " 'sampler': <torch.utils.data.sampler.RandomSampler at 0x7f16e36bd040>,\n",
       " 'batch_sampler': <torch.utils.data.sampler.BatchSampler at 0x7f16e36bddc0>,\n",
       " 'generator': None,\n",
       " 'collate_fn': <function torch.utils.data._utils.collate.default_collate(batch)>,\n",
       " 'persistent_workers': False,\n",
       " '_DataLoader__initialized': True,\n",
       " '_IterableDataset_len_called': None,\n",
       " '_iterator': None}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0a05b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                          | 0/32 [00:00<?, ?it/s]/tmp/ipykernel_2315946/529621054.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "100%|█████████████████████████████████████████████████| 32/32 [00:14<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Loss 0.20957337319850922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 32/32 [00:14<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "Loss 0.3458373546600342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch in loop:\n",
    "        \n",
    "        optim.zero_grad() # Want gradients initialized and set to 0\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        labels=labels)\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}')\n",
    "    print(f'Loss {loss.item()}')\n",
    "#         loop.set_description(f'Epoch {epoch}')\n",
    "#         loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b73bbc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trainer\n",
    "\n",
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir='output_files',\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "597d4bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "292ed159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umar.salman/G42/nlp2sqlEnv/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 507\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n",
      "/tmp/ipykernel_2315946/529621054.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:29, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=64, training_loss=0.2169383466243744, metrics={'train_runtime': 30.0868, 'train_samples_per_second': 33.703, 'train_steps_per_second': 2.127, 'total_flos': 134478511884288.0, 'train_loss': 0.2169383466243744, 'epoch': 2.0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb9f51bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d45c37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
