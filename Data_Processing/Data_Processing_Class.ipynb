{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee766ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from more_itertools import locate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5f164cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Paths = {\n",
    "    'Data': './../Data/',\n",
    "    'Chia_w_scope': './../Data/chia_with_scope/',\n",
    "    'Chia_wo_scope': './../Data/chia_without_scope/',\n",
    "}\n",
    "\n",
    "\n",
    "entity_types = ['Condition', 'Drug', 'Procedure', 'Measurement', 'Observation', 'Person', 'Device', \\\n",
    "    'Value', 'Temporal', 'Qualifier', 'Negation']\n",
    "\n",
    "relation_type = ['OR', 'AND', 'Has_qualifier', 'Has_value', 'Has_negation', 'Has_temporal', 'Has_context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ce1f889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NCT00599924_inc.ann',\n",
       " 'NCT02974686_inc.ann',\n",
       " 'NCT03209687_exc.ann',\n",
       " 'NCT03100513_exc.txt',\n",
       " 'NCT02053246_exc.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(Paths['Chia_wo_scope'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "371ffd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "def get_Input_Files(file_name):\n",
    "\n",
    "    inputfiles = set()\n",
    "    for f in os.listdir(Paths[file_name]):\n",
    "        if f.endswith('.ann'):\n",
    "            inputfiles.add(f.split('.')[0].split('_')[0])\n",
    "    input_files = list(inputfiles)\n",
    "    print(len(inputfiles))\n",
    "#     return inputfiles\n",
    "\n",
    "get_Input_Files('Chia_w_scope')\n",
    "get_Input_Files('Chia_wo_scope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48eeeaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Preparation:\n",
    "    def __init__(self, path, relation_type, entity_types):\n",
    "        self.path = path\n",
    "        self.entity_types = entity_types\n",
    "        self.relation_type = relation_type\n",
    "        self.ignore_files = []\n",
    "        self.input_files = []\n",
    "        self.globalEntities = set()\n",
    "        \n",
    "        print('Data_Preparation Initialized...')\n",
    "        \n",
    "    ###################################################################### HELPER FUNCTIONS\n",
    "        \n",
    "    def checkEntityValue(self, e):\n",
    "        \"\"\"\n",
    "        Helper Function for get_annotation_relations\n",
    "        \"\"\"\n",
    "        if e.startswith('T'):\n",
    "            return e.strip()\n",
    "        else:\n",
    "            return e.split(':')[-1].strip()\n",
    "        \n",
    "    \n",
    "    def removePunctuation(self, word):\n",
    "        \"\"\"\n",
    "        Helper Function for get_Entity_Tags\n",
    "        \"\"\"\n",
    "        word = re.sub(r'^(\\.|,|\\(|\\))', '', word)\n",
    "        word = re.sub(r'(\\.|,|\\(|\\))$', '', word)\n",
    "        return word\n",
    "    \n",
    "    def cleanEntityTokens(self, txt):\n",
    "        \"\"\"\n",
    "        Clean the tokens from / and - for words in entities\n",
    "        \"\"\"\n",
    "        txt = txt.replace('/',' ')\n",
    "        txt = txt.replace('-',' ')\n",
    "        txt = txt.replace(';',' ')\n",
    "        txt = re.sub(r' {2,}', ' ',txt)\n",
    "        txt = txt.strip()\n",
    "        \n",
    "        return txt.split()\n",
    "    \n",
    "    def readTxt(self, txt_file):\n",
    "        with open(txt_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            text_array = f.read()\n",
    "        print(text_array)\n",
    "        \n",
    "    def readAnn(self, ann_file):\n",
    "        with open(ann_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            text_array = f.read()\n",
    "        print(text_array)\n",
    "        \n",
    "    def printFiles(self, file_name, file):\n",
    "        \"\"\"\n",
    "        Helper function to print files without manual viewing them\n",
    "        \"\"\"\n",
    "        ann_file = f\"{Paths[file_name]}{file}.ann\"\n",
    "        txt_file = f\"{Paths[file_name]}{file}.txt\"\n",
    "        self.readAnn(ann_file)\n",
    "        self.readTxt(txt_file)\n",
    "    \n",
    "    \n",
    "    ######################################################################\n",
    "    \n",
    "    def getInputFiles(self, file_name):\n",
    "        \"\"\"\n",
    "        file_name: 'Chia_w_scope' or 'Chia_wo_scope'\n",
    "        \"\"\"\n",
    "        inputfiles = set()\n",
    "        for f in os.listdir(Paths[file_name]):\n",
    "            if f.endswith('.ann'):\n",
    "                inputfiles.add(f.split('.')[0].split('_')[0])\n",
    "        self.input_files = list(inputfiles)\n",
    "        return inputfiles\n",
    "\n",
    "    def ignoreFiles(self, text_array):\n",
    "        match = re.findall(r'^( {1,}\\n$|NA {0,}\\n$)',text_array[0])\n",
    "        if len(match):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def get_annotation_entities(self, ann_file):\n",
    "        \"\"\"\n",
    "        Get all entities which correspond to the entities mentioned in the entity types.\n",
    "        \"\"\"\n",
    "        entities = []\n",
    "        with open(ann_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                if line.startswith('T'):\n",
    "                    assert len(line.strip().split('\\t')) == 3\n",
    "                    entity_identity = line.strip().split('\\t')[0]\n",
    "                    entity_token = line.strip().split('\\t')[-1]\n",
    "                    \n",
    "                    if ';' in line.strip().split('\\t')[1]:\n",
    "                        line = line.replace(';',' ')\n",
    "                        term = line.strip().split('\\t')[1].split()\n",
    "                        term[-1] = str(max([int(v) for v in term[1:]]))\n",
    "                        term[1] = str(min([int(v) for v in term[1:]]))\n",
    "                    else:\n",
    "                        term = line.strip().split('\\t')[1].split()\n",
    "                        \n",
    "                    self.globalEntities.add(term[0])\n",
    "                    \n",
    "                    if (self.entity_types != None) and (term[0] not in self.entity_types): continue\n",
    "                    if int(term[-1]) <= int(term[1]):\n",
    "                        raise RuntimeError('Starting and Ending Indices are off.')\n",
    "                    entities.append((entity_identity, int(term[1]), int(term[-1]), term[0], entity_token))\n",
    "                    \n",
    "        return sorted(entities, key=lambda x: (x[2]))\n",
    "    \n",
    "    def remove_overlap_entities(self, sorted_entities):\n",
    "        \"\"\"\n",
    "        If you want to get the largest overlap of entity so two words don't have different entities\n",
    "        \n",
    "        Here we just use the uncommented part to get the unique entities which we are considering.\n",
    "        \"\"\"\n",
    "#         keep_entities = []\n",
    "#         for idx, entity in enumerate(sorted_entities):\n",
    "#             if idx == 0:\n",
    "#                 keep_entities.append(entity)\n",
    "#                 last_keep = entity\n",
    "#                 continue\n",
    "#             if entity[1] < last_keep[2]:\n",
    "#                 if entity[2]-entity[1] > last_keep[2]-last_keep[1]:\n",
    "#                     last_keep = entity\n",
    "#                     keep_entities[-1] = last_keep\n",
    "#             elif entity[1] == last_keep[2]:\n",
    "#                 last_keep = (last_keep[1], entity[2], last_keep[-1])\n",
    "#                 keep_entities[-1] = last_keep\n",
    "#             else:\n",
    "#                 last_keep = entity\n",
    "#                 keep_entities.append(entity)\n",
    "\n",
    "        keep_entities = sorted_entities\n",
    "\n",
    "        uniqueEntity = []        \n",
    "        for ent in keep_entities:\n",
    "            uniqueEntity.append(ent[0])\n",
    "\n",
    "        return keep_entities, uniqueEntity\n",
    "\n",
    "\n",
    "    # https://datagy.io/python-list-find-all-index/\n",
    "    def get_annotation_relations(self, ann_file, uniqueEntity):\n",
    "        \"\"\"\n",
    "        Gives all relations corresponding to the relations mentioned in relations_type\n",
    "        And make sure they are relations between entities that are mentioned in entity_types\n",
    "        \"\"\"\n",
    "        relations = []\n",
    "        with open(ann_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                if line.startswith('R') or line.startswith('*'):\n",
    "                    assert len(line.strip().split('\\t')) == 2 # ['R1', 'Has_qualifier Arg1:T6 Arg2:T5']\n",
    "                    if line.strip().split('\\t')[1].split()[0] not in relation_type: continue\n",
    "\n",
    "                    rel = line.strip().split('\\t')[0]\n",
    "                    rel_type = line.strip().split('\\t')[1].split()[0]\n",
    "                    entities = line.strip().split('\\t')[1].split()[1:]\n",
    "                    entities= [self.checkEntityValue(e) for e in entities]\n",
    "                    entities = [e for e in entities if e in uniqueEntity]\n",
    "                    entities = ' '.join(entities)\n",
    "                    match = re.findall(r'^T[0-9]+ T[0-9]+$',entities)\n",
    "                    if len(match):\n",
    "                        pass\n",
    "                    else:\n",
    "                        continue\n",
    "                    assert len(entities.split()) == 2\n",
    "                    relations.append((rel, rel_type, entities))\n",
    "\n",
    "        return relations\n",
    "    \n",
    "    \n",
    "    def get_text(self, txt_file, file):\n",
    "        \"\"\"\n",
    "        Get raw text\n",
    "        \"\"\"\n",
    "        with open(txt_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            text_array = f.readlines()\n",
    "            if file in ['NCT02348918_exc', 'NCT02348918_inc', 'NCT01735955_exc']: # Inconsistent offsets (Line breaks)\n",
    "                text = ' '.join([i.strip() for i in text_array])\n",
    "            else:\n",
    "                text = '  '.join([i.strip() for i in text_array])\n",
    "        \n",
    "        return text, text_array\n",
    "    \n",
    "    \n",
    "    def get_text_array(self,text_array):\n",
    "        \"\"\"\n",
    "        Get cleaned text in array form\n",
    "        \"\"\"\n",
    "        \n",
    "        globalText = []\n",
    "        offset = 0\n",
    "        for txt in text_array:\n",
    "            textlen = len(txt)\n",
    "            \n",
    "            txt = txt.replace('/',' ')\n",
    "            txt = txt.replace('-',' ')\n",
    "            txt = txt.replace(';',' ')\n",
    "            txt = re.sub(r' {2,}', ' ',txt)\n",
    "            txt = txt.replace('.\\n','')\n",
    "            txt = txt.replace('\\n', '')\n",
    "            txt = txt.strip()\n",
    "\n",
    "            globalText.append(([self.removePunctuation(w) for w in txt.split()], offset, offset + textlen)) \n",
    "            offset += textlen\n",
    "\n",
    "        return globalText\n",
    "    \n",
    "    def get_NER_Tags(self, globalText, keep_entities):\n",
    "        \"\"\"\n",
    "        Get NER Tags for each token in a sentence.\n",
    "        Then also return a list of the entity identity e.g. T1, T2 etc.\n",
    "        \"\"\"\n",
    "        WORDS, TAGS, IDENTITY = [], [], []\n",
    "        offset = 10\n",
    "        for text in globalText:\n",
    "            words = text[0]\n",
    "            tags = ['O']*len(words)\n",
    "            entity_identity = ['X']*len(words)\n",
    "            sent_indices = set()\n",
    "            for k in keep_entities:\n",
    "                # Using 10 as an offset for wrong offset entries in inc/exc files\n",
    "                # Only look at entities if start and stop indices with an offset match\n",
    "                if k[1] >= (text[1]-offset) and k[2] <= (text[2]+offset): \n",
    "                    clean_tokens = self.cleanEntityTokens(k[-1])\n",
    "                    break_down = [self.removePunctuation(v) for v in clean_tokens] # Get all the tokens (punc removed) from entities\n",
    "                    main_index = 0\n",
    "                    label = ''\n",
    "                    for i, w in enumerate(break_down): # Go over entity tokens\n",
    "                        indices = list(locate(words, lambda x: x == w)) # See if tokens is in sentence\n",
    "\n",
    "                        if i == 0:\n",
    "                            try:\n",
    "                                main_index = indices[0]\n",
    "                                if len(break_down) > 1: label = 'B-'\n",
    "                            except:\n",
    "                                if len(w) <= offset:\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    pass\n",
    "#                                     raise RuntimeError('Word Length greater than offset')\n",
    "                        else:\n",
    "                            label = 'I-'\n",
    "                        indices= list(filter(lambda x: x >= main_index, indices))\n",
    "                        indices= list(filter(lambda x: x not in sent_indices, indices))\n",
    "                        if len(indices) != 0:\n",
    "                            sent_indices.add(indices[0])\n",
    "                            tags[indices[0]] = label + k[3]\n",
    "                            entity_identity[indices[0]] = k[0]\n",
    "            assert len(words) == len(tags) == len(entity_identity)\n",
    "            WORDS.append(words)\n",
    "            TAGS.append(tags) \n",
    "            IDENTITY.append(entity_identity)\n",
    "        return WORDS, TAGS, IDENTITY\n",
    "    \n",
    "    def save_to_df(self, FILES, CRITERIA, TEXT, GROUP_ENTITIES, RELATIONS, TOKENS, ENTITIES):\n",
    "        \n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        df['File'] = pd.Series(FILES) \n",
    "        df['Criteria'] = pd.Series(CRITERIA) \n",
    "        df['Text'] = pd.Series(TEXT)\n",
    "        df['Group_Entities'] = pd.Series(GROUP_ENTITIES)\n",
    "        df['Relations'] = pd.Series(RELATIONS)\n",
    "        df['Tokens'] = pd.Series(TOKENS)\n",
    "        df['Entities'] = pd.Series(ENTITIES) # (Entity Name, Entity Identity)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def run(self, file_name):\n",
    "        \"\"\"\n",
    "        Run on all files\n",
    "        \"\"\"\n",
    "        inputfiles = self.getInputFiles(file_name)\n",
    "        \n",
    "        FILES, CRITERIA, TEXT, GROUP_ENTITIES, RELATIONS, TOKENS, ENTITIES = [], [], [], [], [], [], []\n",
    "        for infile in inputfiles:\n",
    "            for t in [\"inc\", \"exc\"]:\n",
    "                file = f\"{infile}_{t}\"\n",
    "                ann_file = f\"{Paths[file_name]}{file}.ann\"\n",
    "                txt_file = f\"{Paths[file_name]}{file}.txt\"\n",
    "                \n",
    "                text, text_array = self.get_text(txt_file, file)\n",
    "                ignore = self.ignoreFiles(text_array)\n",
    "                if ignore: \n",
    "                    self.ignore_files.append(file)\n",
    "                    continue\n",
    "                sorted_entities = self.get_annotation_entities(ann_file)\n",
    "                entities, uniqueEntity = self.remove_overlap_entities(sorted_entities)\n",
    "                relations = self.get_annotation_relations(ann_file, uniqueEntity)\n",
    "                global_text_array = self.get_text_array(text_array)\n",
    "                words, tags, entity_identity = self.get_NER_Tags(global_text_array, entities)           \n",
    "                \n",
    "                FILES.append(file)\n",
    "                CRITERIA.append(t)\n",
    "                TEXT.append(text_array)\n",
    "                GROUP_ENTITIES.append(entities)\n",
    "                RELATIONS.append(relations)\n",
    "                TOKENS.append(words)\n",
    "                ENTITIES.append((tags, entity_identity))\n",
    "#             break\n",
    "                           \n",
    "        df = self.save_to_df(FILES, CRITERIA, TEXT, GROUP_ENTITIES, RELATIONS, TOKENS, ENTITIES)       \n",
    "        return df\n",
    "                \n",
    "                \n",
    "    def main(self,files_name):\n",
    "        \"\"\"\n",
    "        Give list of files and from the files extract entities, tokens and relations and save in dataframe format\n",
    "        \"\"\"\n",
    "        \n",
    "        df = self.run(files_name)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05944c0f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_Preparation Initialized...\n"
     ]
    }
   ],
   "source": [
    "dataPrep = Data_Preparation(Paths, relation_type, entity_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38de383f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files = ['Chia_w_scope', 'Chia_wo_scope']\n",
    "df = dataPrep.main(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75204caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chia_w_scope:  1950\n",
      "Chia_wo_scope:  1950\n"
     ]
    }
   ],
   "source": [
    "print('Chia_w_scope: ',len(df))\n",
    "print('Chia_wo_scope: ',len(dataPrep.main(files[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1b61d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Criteria</th>\n",
       "      <th>Text</th>\n",
       "      <th>Group_Entities</th>\n",
       "      <th>Relations</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT02152696_inc</td>\n",
       "      <td>inc</td>\n",
       "      <td>[Female with a persisting pregnancy of unknown...</td>\n",
       "      <td>[(T1, 0, 6, Person, Female), (T2, 25, 34, Cond...</td>\n",
       "      <td>[(R1, Has_qualifier, T2 T3), (R2, Has_value, T...</td>\n",
       "      <td>[[Female, with, a, persisting, pregnancy, of, ...</td>\n",
       "      <td>([[Person, O, O, O, Condition, O, B-Qualifier,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT02152696_exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>[Hemodynamically unstable in need of acute tre...</td>\n",
       "      <td>[(T1, 0, 24, Condition, Hemodynamically unstab...</td>\n",
       "      <td>[(R1, Has_value, T2 T4), (R2, Has_temporal, T2...</td>\n",
       "      <td>[[Hemodynamically, unstable, in, need, of, acu...</td>\n",
       "      <td>([[B-Condition, I-Condition, O, O, O, O, O], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCT02476461_inc</td>\n",
       "      <td>inc</td>\n",
       "      <td>[symptomatic Dupuytrens contracture with palpa...</td>\n",
       "      <td>[(T2, 0, 11, Qualifier, symptomatic), (T1, 12,...</td>\n",
       "      <td>[(R1, Has_value, T5 T6), (R2, Has_qualifier, T...</td>\n",
       "      <td>[[symptomatic, Dupuytrens, contracture, with, ...</td>\n",
       "      <td>([[Qualifier, B-Condition, I-Condition, O, B-C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCT02476461_exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>[previous treated dupuytrens contracture same ...</td>\n",
       "      <td>[(T1, 0, 8, Temporal, previous), (T2, 9, 16, Q...</td>\n",
       "      <td>[(R1, Has_qualifier, T3 T4), (R2, Has_qualifie...</td>\n",
       "      <td>[[previous, treated, dupuytrens, contracture, ...</td>\n",
       "      <td>([[Temporal, Qualifier, B-Condition, I-Conditi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCT03226080_inc</td>\n",
       "      <td>inc</td>\n",
       "      <td>[ASA I-IV Age 55 or older Scheduled for operat...</td>\n",
       "      <td>[(T1, 0, 3, Measurement, ASA), (T2, 4, 8, Valu...</td>\n",
       "      <td>[(R1, Has_value, T3 T4), (R2, Has_qualifier, T...</td>\n",
       "      <td>[[ASA, I, IV, Age, 55, or, older, Scheduled, f...</td>\n",
       "      <td>([[Measurement, B-Value, I-Value, Person, B-Va...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              File Criteria  \\\n",
       "0  NCT02152696_inc      inc   \n",
       "1  NCT02152696_exc      exc   \n",
       "2  NCT02476461_inc      inc   \n",
       "3  NCT02476461_exc      exc   \n",
       "4  NCT03226080_inc      inc   \n",
       "\n",
       "                                                Text  \\\n",
       "0  [Female with a persisting pregnancy of unknown...   \n",
       "1  [Hemodynamically unstable in need of acute tre...   \n",
       "2  [symptomatic Dupuytrens contracture with palpa...   \n",
       "3  [previous treated dupuytrens contracture same ...   \n",
       "4  [ASA I-IV Age 55 or older Scheduled for operat...   \n",
       "\n",
       "                                      Group_Entities  \\\n",
       "0  [(T1, 0, 6, Person, Female), (T2, 25, 34, Cond...   \n",
       "1  [(T1, 0, 24, Condition, Hemodynamically unstab...   \n",
       "2  [(T2, 0, 11, Qualifier, symptomatic), (T1, 12,...   \n",
       "3  [(T1, 0, 8, Temporal, previous), (T2, 9, 16, Q...   \n",
       "4  [(T1, 0, 3, Measurement, ASA), (T2, 4, 8, Valu...   \n",
       "\n",
       "                                           Relations  \\\n",
       "0  [(R1, Has_qualifier, T2 T3), (R2, Has_value, T...   \n",
       "1  [(R1, Has_value, T2 T4), (R2, Has_temporal, T2...   \n",
       "2  [(R1, Has_value, T5 T6), (R2, Has_qualifier, T...   \n",
       "3  [(R1, Has_qualifier, T3 T4), (R2, Has_qualifie...   \n",
       "4  [(R1, Has_value, T3 T4), (R2, Has_qualifier, T...   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [[Female, with, a, persisting, pregnancy, of, ...   \n",
       "1  [[Hemodynamically, unstable, in, need, of, acu...   \n",
       "2  [[symptomatic, Dupuytrens, contracture, with, ...   \n",
       "3  [[previous, treated, dupuytrens, contracture, ...   \n",
       "4  [[ASA, I, IV, Age, 55, or, older, Scheduled, f...   \n",
       "\n",
       "                                            Entities  \n",
       "0  ([[Person, O, O, O, Condition, O, B-Qualifier,...  \n",
       "1  ([[B-Condition, I-Condition, O, O, O, O, O], [...  \n",
       "2  ([[Qualifier, B-Condition, I-Condition, O, B-C...  \n",
       "3  ([[Temporal, Qualifier, B-Condition, I-Conditi...  \n",
       "4  ([[Measurement, B-Value, I-Value, Person, B-Va...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4422d675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Criteria</th>\n",
       "      <th>Text</th>\n",
       "      <th>Group_Entities</th>\n",
       "      <th>Relations</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT02152696_inc</td>\n",
       "      <td>inc</td>\n",
       "      <td>[Female with a persisting pregnancy of unknown...</td>\n",
       "      <td>[(T1, 0, 6, Person, Female), (T2, 25, 34, Cond...</td>\n",
       "      <td>[(R1, Has_qualifier, T2 T3), (R2, Has_value, T...</td>\n",
       "      <td>[[Female, with, a, persisting, pregnancy, of, ...</td>\n",
       "      <td>([[Person, O, O, O, Condition, O, B-Qualifier,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT02152696_exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>[Hemodynamically unstable in need of acute tre...</td>\n",
       "      <td>[(T1, 0, 24, Condition, Hemodynamically unstab...</td>\n",
       "      <td>[(R1, Has_value, T2 T4), (R2, Has_temporal, T2...</td>\n",
       "      <td>[[Hemodynamically, unstable, in, need, of, acu...</td>\n",
       "      <td>([[B-Condition, I-Condition, O, O, O, O, O], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCT02476461_inc</td>\n",
       "      <td>inc</td>\n",
       "      <td>[symptomatic Dupuytrens contracture with palpa...</td>\n",
       "      <td>[(T2, 0, 11, Qualifier, symptomatic), (T1, 12,...</td>\n",
       "      <td>[(R1, Has_value, T5 T6), (R2, Has_qualifier, T...</td>\n",
       "      <td>[[symptomatic, Dupuytrens, contracture, with, ...</td>\n",
       "      <td>([[Qualifier, B-Condition, I-Condition, O, B-C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCT02476461_exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>[previous treated dupuytrens contracture same ...</td>\n",
       "      <td>[(T1, 0, 8, Temporal, previous), (T2, 9, 16, Q...</td>\n",
       "      <td>[(R1, Has_qualifier, T3 T4), (R2, Has_qualifie...</td>\n",
       "      <td>[[previous, treated, dupuytrens, contracture, ...</td>\n",
       "      <td>([[Temporal, Qualifier, B-Condition, I-Conditi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCT03226080_inc</td>\n",
       "      <td>inc</td>\n",
       "      <td>[ASA I-IV Age 55 or older Scheduled for operat...</td>\n",
       "      <td>[(T1, 0, 3, Measurement, ASA), (T2, 4, 8, Valu...</td>\n",
       "      <td>[(R1, Has_value, T3 T4), (R2, Has_qualifier, T...</td>\n",
       "      <td>[[ASA, I, IV, Age, 55, or, older, Scheduled, f...</td>\n",
       "      <td>([[Measurement, B-Value, I-Value, Person, B-Va...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              File Criteria  \\\n",
       "0  NCT02152696_inc      inc   \n",
       "1  NCT02152696_exc      exc   \n",
       "2  NCT02476461_inc      inc   \n",
       "3  NCT02476461_exc      exc   \n",
       "4  NCT03226080_inc      inc   \n",
       "\n",
       "                                                Text  \\\n",
       "0  [Female with a persisting pregnancy of unknown...   \n",
       "1  [Hemodynamically unstable in need of acute tre...   \n",
       "2  [symptomatic Dupuytrens contracture with palpa...   \n",
       "3  [previous treated dupuytrens contracture same ...   \n",
       "4  [ASA I-IV Age 55 or older Scheduled for operat...   \n",
       "\n",
       "                                      Group_Entities  \\\n",
       "0  [(T1, 0, 6, Person, Female), (T2, 25, 34, Cond...   \n",
       "1  [(T1, 0, 24, Condition, Hemodynamically unstab...   \n",
       "2  [(T2, 0, 11, Qualifier, symptomatic), (T1, 12,...   \n",
       "3  [(T1, 0, 8, Temporal, previous), (T2, 9, 16, Q...   \n",
       "4  [(T1, 0, 3, Measurement, ASA), (T2, 4, 8, Valu...   \n",
       "\n",
       "                                           Relations  \\\n",
       "0  [(R1, Has_qualifier, T2 T3), (R2, Has_value, T...   \n",
       "1  [(R1, Has_value, T2 T4), (R2, Has_temporal, T2...   \n",
       "2  [(R1, Has_value, T5 T6), (R2, Has_qualifier, T...   \n",
       "3  [(R1, Has_qualifier, T3 T4), (R2, Has_qualifie...   \n",
       "4  [(R1, Has_value, T3 T4), (R2, Has_qualifier, T...   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [[Female, with, a, persisting, pregnancy, of, ...   \n",
       "1  [[Hemodynamically, unstable, in, need, of, acu...   \n",
       "2  [[symptomatic, Dupuytrens, contracture, with, ...   \n",
       "3  [[previous, treated, dupuytrens, contracture, ...   \n",
       "4  [[ASA, I, IV, Age, 55, or, older, Scheduled, f...   \n",
       "\n",
       "                                            Entities  \n",
       "0  ([[Person, O, O, O, Condition, O, B-Qualifier,...  \n",
       "1  ([[B-Condition, I-Condition, O, O, O, O, O], [...  \n",
       "2  ([[Qualifier, B-Condition, I-Condition, O, B-C...  \n",
       "3  ([[Temporal, Qualifier, B-Condition, I-Conditi...  \n",
       "4  ([[Measurement, B-Value, I-Value, Person, B-Va...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPrep.main(files[1]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc4392ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NCT03106389_inc',\n",
       " 'NCT03106389_exc',\n",
       " 'NCT03198910_exc',\n",
       " 'NCT03082573_exc',\n",
       " 'NCT01088750_exc',\n",
       " 'NCT02607163_exc',\n",
       " 'NCT02748330_exc',\n",
       " 'NCT03389061_exc',\n",
       " 'NCT02504203_exc',\n",
       " 'NCT02620904_exc',\n",
       " 'NCT02256943_exc',\n",
       " 'NCT03134196_inc',\n",
       " 'NCT03134196_exc',\n",
       " 'NCT02590653_exc',\n",
       " 'NCT03045562_exc',\n",
       " 'NCT02953873_exc',\n",
       " 'NCT03615508_exc',\n",
       " 'NCT03263481_inc',\n",
       " 'NCT03263481_exc',\n",
       " 'NCT02969876_exc',\n",
       " 'NCT03350815_exc',\n",
       " 'NCT03156855_exc',\n",
       " 'NCT02918409_exc',\n",
       " 'NCT01490034_exc',\n",
       " 'NCT03372304_exc',\n",
       " 'NCT01352598_exc',\n",
       " 'NCT02219880_exc',\n",
       " 'NCT02222272_exc',\n",
       " 'NCT01742117_exc',\n",
       " 'NCT02399033_exc',\n",
       " 'NCT03088904_inc',\n",
       " 'NCT03088904_exc',\n",
       " 'NCT03077204_exc',\n",
       " 'NCT02256956_exc',\n",
       " 'NCT03011177_exc',\n",
       " 'NCT02785549_exc',\n",
       " 'NCT03620526_exc',\n",
       " 'NCT02715518_exc',\n",
       " 'NCT02457442_exc',\n",
       " 'NCT03278548_exc',\n",
       " 'NCT02478346_exc',\n",
       " 'NCT03355157_exc',\n",
       " 'NCT02323399_exc',\n",
       " 'NCT02944604_exc',\n",
       " 'NCT02270970_exc',\n",
       " 'NCT01078051_exc',\n",
       " 'NCT02408120_exc',\n",
       " 'NCT01944800_exc',\n",
       " 'NCT03228238_exc',\n",
       " 'NCT02042287_exc']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPrep.ignore_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebeb2715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Competing_trial',\n",
       " 'Condition',\n",
       " 'Context_Error',\n",
       " 'Device',\n",
       " 'Drug',\n",
       " 'Grammar_Error',\n",
       " 'Informed_consent',\n",
       " 'Intoxication_considerations',\n",
       " 'Line',\n",
       " 'Measurement',\n",
       " 'Mood',\n",
       " 'Multiplier',\n",
       " 'Negation',\n",
       " 'Non-query-able',\n",
       " 'Non-representable',\n",
       " 'Not_a_criteria',\n",
       " 'Observation',\n",
       " 'Parsing_Error',\n",
       " 'Person',\n",
       " 'Post-eligibility',\n",
       " 'Pregnancy_considerations',\n",
       " 'Procedure',\n",
       " 'Qualifier',\n",
       " 'Reference_point',\n",
       " 'Scope',\n",
       " 'Subjective_judgement',\n",
       " 'Temporal',\n",
       " 'Undefined_semantics',\n",
       " 'Value',\n",
       " 'Visit',\n",
       " 'c-Requires_causality'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPrep.globalEntities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "628b8305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1\tPerson 0 3\tAge\n",
      "T2\tValue 4 17\t<18 years old\n",
      "R1\tHas_value Arg1:T1 Arg2:T2\t\n",
      "T3\tPost-eligibility 19 75\tPatient unable to communicate or to understand the study\n",
      "T4\tPost-eligibility 77 121\tPatient refusing to participate to the study\n",
      "T5\tCondition 123 139\tcontraindication\n",
      "T6\tProcedure 143 154\tlaparoscopy\n",
      "R2\tAND Arg1:T5 Arg2:T6\t\n",
      "\n",
      "Age <18 years old\n",
      "Patient unable to communicate or to understand the study\n",
      "Patient refusing to participate to the study\n",
      "contraindication to laparoscopy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataPrep.printFiles('Chia_w_scope', 'NCT01346436_exc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83f3b679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1\tNon-query-able 0 2\tNA\n",
      "\n",
      "NA\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataPrep.printFiles('Chia_w_scope', 'NCT03615508_exc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1845cfb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Criteria</th>\n",
       "      <th>Text</th>\n",
       "      <th>Group_Entities</th>\n",
       "      <th>Relations</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT01815580_inc</td>\n",
       "      <td>inc</td>\n",
       "      <td>[Adult men who have sex with men, and transgen...</td>\n",
       "      <td>[(T1, 0, 5, Person, Adult), (T2, 6, 31, Person...</td>\n",
       "      <td>[(*, OR, T2 T3), (R1, Has_value, T4 T5), (R4, ...</td>\n",
       "      <td>[[Adult, men, who, have, sex, with, men, and, ...</td>\n",
       "      <td>([[Person, B-Person, I-Person, I-Person, I-Per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT01815580_exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>[Prior receipt of investigational anti-HIV vac...</td>\n",
       "      <td>[(T1, 0, 5, Temporal, Prior), (T2, 17, 32, Qua...</td>\n",
       "      <td>[(R1, Has_qualifier, T3 T2), (R2, Has_temporal...</td>\n",
       "      <td>[[Prior, receipt, of, investigational, anti, H...</td>\n",
       "      <td>([[Temporal, O, O, Qualifier, B-Drug, I-Drug, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCT03195153_inc</td>\n",
       "      <td>inc</td>\n",
       "      <td>[diabetic patient;\\n, therapy with aspirin and...</td>\n",
       "      <td>[(T1, 0, 8, Condition, diabetic), (T2, 32, 39,...</td>\n",
       "      <td>[(*, OR, T2 T3)]</td>\n",
       "      <td>[[diabetic, patient], [therapy, with, aspirin,...</td>\n",
       "      <td>([[Condition, O], [O, O, Drug, O, Drug], [O, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCT03195153_exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>[not diabetic patient;\\n, patients in dual ant...</td>\n",
       "      <td>[(T2, 0, 3, Negation, not), (T1, 4, 12, Condit...</td>\n",
       "      <td>[(R1, Has_negation, T1 T2), (R2, Has_qualifier...</td>\n",
       "      <td>[[not, diabetic, patient], [patients, in, dual...</td>\n",
       "      <td>([[Negation, Condition, O], [O, O, B-Procedure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCT03115151_inc</td>\n",
       "      <td>inc</td>\n",
       "      <td>[Adult subjects aged 18 years or older\\n, Sche...</td>\n",
       "      <td>[(T1, 0, 5, Person, Adult), (T2, 15, 19, Perso...</td>\n",
       "      <td>[(R1, Has_value, T2 T3), (R2, AND, T1 T2), (R3...</td>\n",
       "      <td>[[Adult, subjects, aged, 18, years, or, older]...</td>\n",
       "      <td>([[Person, O, Person, B-Value, I-Value, I-Valu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>NCT01824537_exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>[Volunteers must not have been vaccinated agai...</td>\n",
       "      <td>[(T1, 16, 19, Negation, not), (T2, 20, 29, Tem...</td>\n",
       "      <td>[(R1, AND, T3 T4), (R2, Has_negation, T3 T1), ...</td>\n",
       "      <td>[[Volunteers, must, not, have, been, vaccinate...</td>\n",
       "      <td>([[O, O, Negation, B-Temporal, I-Temporal, Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>NCT02498483_inc</td>\n",
       "      <td>inc</td>\n",
       "      <td>[Apgar score at 5 minutes &gt;7\\n, birthweight gr...</td>\n",
       "      <td>[(T1, 0, 11, Measurement, Apgar score), (T3, 1...</td>\n",
       "      <td>[(R1, Has_value, T1 T2), (R2, Has_temporal, T1...</td>\n",
       "      <td>[[Apgar, score, at, 5, minutes, &gt;7], [birthwei...</td>\n",
       "      <td>([[B-Measurement, I-Measurement, B-Temporal, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>NCT02498483_exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>[Newborns of substance abusing mothers.\\n, New...</td>\n",
       "      <td>[(T1, 0, 8, Person, Newborns), (T3, 12, 29, Co...</td>\n",
       "      <td>[(R1, AND, T2 T3), (R2, AND, T5 T6)]</td>\n",
       "      <td>[[Newborns, of, substance, abusing, mothers], ...</td>\n",
       "      <td>([[Person, O, B-Condition, I-Condition, Person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>NCT03506750_inc</td>\n",
       "      <td>inc</td>\n",
       "      <td>[18 years or older\\n, Type 1 or 2 diabetes\\n, ...</td>\n",
       "      <td>[(T1, 0, 17, Value, 18 years or older), (T2, 1...</td>\n",
       "      <td>[(R1, Has_value, T2 T1), (*, OR, T3 T4), (R3, ...</td>\n",
       "      <td>[[18, years, or, older], [Type, 1, or, 2, diab...</td>\n",
       "      <td>([[B-Value, I-Value, I-Value, I-Value], [B-Con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>NCT03506750_exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>[previous retinal vein occlusion.\\n, any intra...</td>\n",
       "      <td>[(T2, 0, 8, Temporal, previous), (T1, 9, 31, C...</td>\n",
       "      <td>[(R1, Has_temporal, T1 T2), (R2, Has_temporal,...</td>\n",
       "      <td>[[previous, retinal, vein, occlusion], [any, i...</td>\n",
       "      <td>([[Temporal, B-Condition, I-Condition, I-Condi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1950 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 File Criteria  \\\n",
       "0     NCT01815580_inc      inc   \n",
       "1     NCT01815580_exc      exc   \n",
       "2     NCT03195153_inc      inc   \n",
       "3     NCT03195153_exc      exc   \n",
       "4     NCT03115151_inc      inc   \n",
       "...               ...      ...   \n",
       "1945  NCT01824537_exc      exc   \n",
       "1946  NCT02498483_inc      inc   \n",
       "1947  NCT02498483_exc      exc   \n",
       "1948  NCT03506750_inc      inc   \n",
       "1949  NCT03506750_exc      exc   \n",
       "\n",
       "                                                   Text  \\\n",
       "0     [Adult men who have sex with men, and transgen...   \n",
       "1     [Prior receipt of investigational anti-HIV vac...   \n",
       "2     [diabetic patient;\\n, therapy with aspirin and...   \n",
       "3     [not diabetic patient;\\n, patients in dual ant...   \n",
       "4     [Adult subjects aged 18 years or older\\n, Sche...   \n",
       "...                                                 ...   \n",
       "1945  [Volunteers must not have been vaccinated agai...   \n",
       "1946  [Apgar score at 5 minutes >7\\n, birthweight gr...   \n",
       "1947  [Newborns of substance abusing mothers.\\n, New...   \n",
       "1948  [18 years or older\\n, Type 1 or 2 diabetes\\n, ...   \n",
       "1949  [previous retinal vein occlusion.\\n, any intra...   \n",
       "\n",
       "                                         Group_Entities  \\\n",
       "0     [(T1, 0, 5, Person, Adult), (T2, 6, 31, Person...   \n",
       "1     [(T1, 0, 5, Temporal, Prior), (T2, 17, 32, Qua...   \n",
       "2     [(T1, 0, 8, Condition, diabetic), (T2, 32, 39,...   \n",
       "3     [(T2, 0, 3, Negation, not), (T1, 4, 12, Condit...   \n",
       "4     [(T1, 0, 5, Person, Adult), (T2, 15, 19, Perso...   \n",
       "...                                                 ...   \n",
       "1945  [(T1, 16, 19, Negation, not), (T2, 20, 29, Tem...   \n",
       "1946  [(T1, 0, 11, Measurement, Apgar score), (T3, 1...   \n",
       "1947  [(T1, 0, 8, Person, Newborns), (T3, 12, 29, Co...   \n",
       "1948  [(T1, 0, 17, Value, 18 years or older), (T2, 1...   \n",
       "1949  [(T2, 0, 8, Temporal, previous), (T1, 9, 31, C...   \n",
       "\n",
       "                                              Relations  \\\n",
       "0     [(*, OR, T2 T3), (R1, Has_value, T4 T5), (R4, ...   \n",
       "1     [(R1, Has_qualifier, T3 T2), (R2, Has_temporal...   \n",
       "2                                      [(*, OR, T2 T3)]   \n",
       "3     [(R1, Has_negation, T1 T2), (R2, Has_qualifier...   \n",
       "4     [(R1, Has_value, T2 T3), (R2, AND, T1 T2), (R3...   \n",
       "...                                                 ...   \n",
       "1945  [(R1, AND, T3 T4), (R2, Has_negation, T3 T1), ...   \n",
       "1946  [(R1, Has_value, T1 T2), (R2, Has_temporal, T1...   \n",
       "1947               [(R1, AND, T2 T3), (R2, AND, T5 T6)]   \n",
       "1948  [(R1, Has_value, T2 T1), (*, OR, T3 T4), (R3, ...   \n",
       "1949  [(R1, Has_temporal, T1 T2), (R2, Has_temporal,...   \n",
       "\n",
       "                                                 Tokens  \\\n",
       "0     [[Adult, men, who, have, sex, with, men, and, ...   \n",
       "1     [[Prior, receipt, of, investigational, anti, H...   \n",
       "2     [[diabetic, patient], [therapy, with, aspirin,...   \n",
       "3     [[not, diabetic, patient], [patients, in, dual...   \n",
       "4     [[Adult, subjects, aged, 18, years, or, older]...   \n",
       "...                                                 ...   \n",
       "1945  [[Volunteers, must, not, have, been, vaccinate...   \n",
       "1946  [[Apgar, score, at, 5, minutes, >7], [birthwei...   \n",
       "1947  [[Newborns, of, substance, abusing, mothers], ...   \n",
       "1948  [[18, years, or, older], [Type, 1, or, 2, diab...   \n",
       "1949  [[previous, retinal, vein, occlusion], [any, i...   \n",
       "\n",
       "                                               Entities  \n",
       "0     ([[Person, B-Person, I-Person, I-Person, I-Per...  \n",
       "1     ([[Temporal, O, O, Qualifier, B-Drug, I-Drug, ...  \n",
       "2     ([[Condition, O], [O, O, Drug, O, Drug], [O, B...  \n",
       "3     ([[Negation, Condition, O], [O, O, B-Procedure...  \n",
       "4     ([[Person, O, Person, B-Value, I-Value, I-Valu...  \n",
       "...                                                 ...  \n",
       "1945  ([[O, O, Negation, B-Temporal, I-Temporal, Pro...  \n",
       "1946  ([[B-Measurement, I-Measurement, B-Temporal, I...  \n",
       "1947  ([[Person, O, B-Condition, I-Condition, Person...  \n",
       "1948  ([[B-Value, I-Value, I-Value, I-Value], [B-Con...  \n",
       "1949  ([[Temporal, B-Condition, I-Condition, I-Condi...  \n",
       "\n",
       "[1950 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b468fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('main_data.csv')\n",
    "# xdf = pd.read_csv('main_data.csv')\n",
    "# xdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f87cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0c2cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf.loc[0]['Entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55857726",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, f in xdf.iterrows():\n",
    "    print(f['Tokens'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de0392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, f in xdf.iterrows():\n",
    "    print(eval(f['Entities'])[0])\n",
    "    print(eval(f['Entities'])[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e869947b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
